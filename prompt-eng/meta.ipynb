{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Prompting\n",
    "\n",
    "Meta prompting is an advanced technique in prompt engineering that emphasizes the structural and syntactical organization of tasks and problems rather than focusing on their specific content. The objective is to create a more abstract, form-driven way of engaging with large language models (LLMs), highlighting patterns and structure over traditional content-focused methods.\n",
    "\n",
    "As outlined by [Zhang et al. (2024)](https://arxiv.org/abs/2311.11482), the defining features of meta prompting include:\n",
    "\n",
    "* Structure-Oriented: Prioritizes the organization and pattern of problems and solutions instead of specific content.\n",
    "* Syntax-Guided: Leverages syntax as a template to shape the expected responses or solutions.\n",
    "* Abstract Frameworks: Uses abstract examples as blueprints, demonstrating the structure of tasks without relying on concrete details.\n",
    "* Domain Versatility: Can be applied across multiple fields, offering structured solutions to diverse problem types.\n",
    "* Categorical Approach: Draws on type theory to organize and categorize components logically, enhancing prompt coherence and precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fmeta.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': 'I want you to act as an expert in solving mathematical problems with these qualities:\\n1. Extremely precise and accurate\\n2. Step-by-step logical reasoning\\n3. Focus on calculating the exact numerical answer\\n4. Double-check your work\\n5. Express the final answer in its simplest form\\n\\nWhen approaching a calculation question, first parse what operation is required, identify the specific numbers and mathematical functions involved, perform the calculation with high precision, verify your result, and provide the answer as a clear numerical value.\\n\\nNow, solve this problem:\\n\\nWhat is 984 * log(2)', 'stream': False, 'options': {'temperature': 0.2, 'num_ctx': 512, 'num_predict': 300, 'top_p': 0.9}}\n",
      "To solve this problem, we need to follow the order of operations (PEMDAS):\n",
      "\n",
      "1. Identify the operation: We are required to find the product of 984 and the logarithm of 2.\n",
      "2. Identify the specific numbers and mathematical functions involved:\n",
      "   - 984 (a constant)\n",
      "   - log(2) (the logarithm base 10, since no base is specified)\n",
      "\n",
      "3. Calculate the logarithm value:\n",
      "\n",
      "log(2) ≈ 0.30103 (using a calculator or a reliable source for logarithmic values)\n",
      "\n",
      "4. Multiply 984 by the calculated logarithm value:\n",
      "\n",
      "984 * 0.30103 ≈ 296.91592\n",
      "\n",
      "5. Double-check the work: We have performed the calculation with high precision and verified our result.\n",
      "\n",
      "6. Express the final answer in its simplest form:\n",
      "Since we are asked for a numerical value, we can provide it as is.\n",
      "\n",
      "The final answer is approximately 296.916.\n",
      "Time taken: 6.579s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## META PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"What is 984 * log(2)\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "\n",
    "META_PROMPT = \"\"\"I want you to act as an expert in solving mathematical problems with these qualities:\n",
    "1. Extremely precise and accurate\n",
    "2. Step-by-step logical reasoning\n",
    "3. Focus on calculating the exact numerical answer\n",
    "4. Double-check your work\n",
    "5. Express the final answer in its simplest form\n",
    "\n",
    "When approaching a calculation question, first parse what operation is required, identify the specific numbers and mathematical functions involved, perform the calculation with high precision, verify your result, and provide the answer as a clear numerical value.\n",
    "\n",
    "Now, solve this problem:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = META_PROMPT + \"\\n\" + MESSAGE\n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(\n",
    "    target=\"ollama\",\n",
    "    model=\"llama3.2:latest\", \n",
    "    prompt=PROMPT, \n",
    "    temperature=0.2,       # Lower temperature for precise calculations\n",
    "    num_ctx=512,           # Increased context for reasoning space\n",
    "    num_predict=300,       # Allow more tokens for step-by-step reasoning\n",
    "    top_p=0.9              # Slightly constrained sampling for mathematical precision\n",
    ")\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
