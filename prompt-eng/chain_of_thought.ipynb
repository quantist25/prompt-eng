{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain-of-Thought Prompting\n",
    "\n",
    "Chain-of-Thought (CoT) prompting enhances complex reasoning by encouraging the model to break down problems into intermediate reasoning steps. When combined with few-shot prompting, it can significantly improve performance on tasks that require multi-step reasoning before arriving at a response.\n",
    "\n",
    "## Automatic Chain-of-Thought (Auto-CoT)\n",
    "\n",
    "Traditionally, using CoT prompting with demonstrations involves manually crafting diverse and effective examples. This manual effort is time-consuming and can lead to less-than-optimal results. To address this, Zhang et al. (2022) introduced Auto-CoT, an automated approach that minimizes manual involvement. Their method uses the prompt “Let’s think step by step” to generate reasoning chains automatically for demonstrations. However, this automatic process is not immune to errors. To reduce the impact of such mistakes, the approach emphasizes the importance of diverse demonstrations.\n",
    "\n",
    "Auto-CoT operates in two main stages:\n",
    "\n",
    "1. **Question Clustering:** Questions from the dataset are grouped into clusters based on similarity or relevance.\n",
    "2. **Demonstration Sampling:** A representative question from each cluster is selected, and its reasoning chain is generated using Zero-Shot-CoT guided by simple heuristics.\n",
    "\n",
    "\n",
    "## References:\n",
    "\n",
    "* (Wei et al. (2022),)[https://arxiv.org/abs/2201.11903]\n",
    "* (OpenAI Documentation for Prompt Engineering)[https://platform.openai.com/docs/guides/prompt-engineering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fchain_of_thought.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': '\\nThe odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\\nA: Let me identify all odd numbers: 9, 15, 1. Adding them: 9 + 15 + 1 = 25. 25 is odd, not even. The answer is False.\\n\\nThe odd numbers in this group add up to an even number: 17, 10, 19, 4, 8, 12, 24.\\nA: Let me identify all odd numbers: 17, 19. Adding them: 17 + 19 = 36. 36 is even. The answer is True.\\n\\nThe odd numbers in this group add up to an even number: 16, 11, 14, 4, 8, 13, 24.\\nA: Let me identify all odd numbers: 11, 13. Adding them: 11 + 13 = 24. 24 is even. The answer is True.\\n\\nThe odd numbers in this group add up to an even number: 17, 9, 10, 12, 13, 4, 2.\\nA: Let me identify all odd numbers: 17, 9, 13. Adding them: 17 + 9 + 13 = 39. 39 is odd, not even. The answer is False.\\n\\nAdd all odd numbers from 1 to 200.\\nStep by step:\\n1. Identify all odd numbers from 1 to 200.\\n2. Calculate their sum.\\n3. Determine if the sum is even or odd.\\nProvide only the final answer as \"True\" if the sum is even, or \"False\" if the sum is odd.\\n', 'stream': False, 'options': {'temperature': 0.7, 'num_ctx': 100, 'num_predict': 100}}\n",
      "To solve this problem, we will follow the steps provided:\n",
      "\n",
      "## Step 1: Identify the numbers to be summed\n",
      "The set of numbers that need to be summed is all integers from 1 to n. However, since the upper limit 'n' is not specified in the question, we can consider a general approach.\n",
      "\n",
      "## Step 2: Calculate the sum of an arithmetic series\n",
      "For any given range (1 to n), the sum of an arithmetic series can be calculated using the formula:\n",
      "Time taken: 5.805s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## CHAIN-OF-THOUGHT PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"200\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "CHAIN_OF_THOUGHT = \\\n",
    "f\"\"\"\n",
    "The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
    "A: Let me identify all odd numbers: 9, 15, 1. Adding them: 9 + 15 + 1 = 25. 25 is odd, not even. The answer is False.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 17, 10, 19, 4, 8, 12, 24.\n",
    "A: Let me identify all odd numbers: 17, 19. Adding them: 17 + 19 = 36. 36 is even. The answer is True.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 16, 11, 14, 4, 8, 13, 24.\n",
    "A: Let me identify all odd numbers: 11, 13. Adding them: 11 + 13 = 24. 24 is even. The answer is True.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 17, 9, 10, 12, 13, 4, 2.\n",
    "A: Let me identify all odd numbers: 17, 9, 13. Adding them: 17 + 9 + 13 = 39. 39 is odd, not even. The answer is False.\n",
    "\n",
    "Add all odd numbers from 1 to {MESSAGE}.\n",
    "Step by step:\n",
    "1. Identify all odd numbers from 1 to {MESSAGE}.\n",
    "2. Calculate their sum.\n",
    "3. Determine if the sum is even or odd.\n",
    "Provide only the final answer as \"True\" if the sum is even, or \"False\" if the sum is odd.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = CHAIN_OF_THOUGHT\n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",  # Make sure this is \"ollama\" not \"open-webui\"\n",
    "                         model=\"llama3.2:latest\",  # Use the exact model name from your list\n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.7,\n",
    "                         num_ctx=100, \n",
    "                         num_predict=100)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
