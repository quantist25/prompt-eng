{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shots Prompting\n",
    "\n",
    "Few-shot prompting can be used as a technique to enable in-context learning where we provide demonstrations in the prompt to steer the model to better performance. The demonstrations serve as conditioning for subsequent examples where we would like the model to generate a response.\n",
    "\n",
    "## References:\n",
    "* [Touvron et al. 2023](https://arxiv.org/pdf/2302.13971.pdf): present few shot properties  when models were scaled to a sufficient size\n",
    "* [Kaplan et al., 2020](https://arxiv.org/abs/2001.08361)\n",
    "* [Brown et al. 2020](https://arxiv.org/abs/2005.14165)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Ffew_shots.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': 'You are a mathematics assistant who provides concise, accurate answers.\\n\\nExamples:\\nQuestion: 1 + 1\\nAnswer: 2\\n\\nQuestion: 987 * 2\\nAnswer: 1974\\n\\nQuestion: 45 / 9\\nAnswer: 5\\n\\nQuestion: log(10)\\nAnswer: 1\\n\\nQuestion: 23^2\\nAnswer: 529\\n\\nQuestion: √25\\nAnswer: 5\\n\\nQuestion: Derivative of x^2\\nAnswer: 2x\\n\\nYour task is to provide only the numerical result without explanation.\\n\\nQuestion: Calculate 984 * log(2)', 'stream': False, 'options': {'temperature': 0.3, 'num_ctx': 512, 'num_predict': 100}}\n",
      "492.192\n",
      "Time taken: 2.509s\n"
     ]
    }
   ],
   "source": [
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Inbound message from user\n",
    "MESSAGE = \"Calculate 984 * log(2)\"\n",
    "\n",
    "#### (2) Enhanced Few-Shot Prompting\n",
    "FEW_SHOT = \"\"\"You are a mathematics assistant who provides concise, accurate answers.\n",
    "\n",
    "Examples:\n",
    "Question: 1 + 1\n",
    "Answer: 2\n",
    "\n",
    "Question: 987 * 2\n",
    "Answer: 1974\n",
    "\n",
    "Question: 45 / 9\n",
    "Answer: 5\n",
    "\n",
    "Question: log(10)\n",
    "Answer: 1\n",
    "\n",
    "Question: 23^2\n",
    "Answer: 529\n",
    "\n",
    "Question: √25\n",
    "Answer: 5\n",
    "\n",
    "Question: Derivative of x^2\n",
    "Answer: 2x\n",
    "\n",
    "Your task is to provide only the numerical result without explanation.\n",
    "\n",
    "Question: \"\"\"\n",
    "\n",
    "PROMPT = FEW_SHOT + MESSAGE\n",
    "\n",
    "#### (3) Model Configuration\n",
    "payload = create_payload(\n",
    "    target=\"ollama\",\n",
    "    model=\"llama3.2:latest\",\n",
    "    prompt=PROMPT,\n",
    "    temperature=0.3,  # Lower temperature for more deterministic math results\n",
    "    num_ctx=512,      # Increased context window for more examples\n",
    "    num_predict=100\n",
    ")\n",
    "\n",
    "# Execute request\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to improve it?\n",
    "\n",
    "Following the findings from [Min et al. (2022)](https://arxiv.org/abs/2202.12837), here are a few more tips about demonstrations/exemplars when doing few-shot:\n",
    "\n",
    "* \"the label space and the distribution of the input text specified by the demonstrations are both important (regardless of whether the labels are correct for individual inputs)\"\n",
    "* the format you use also plays a key role in performance, even if you just use random labels, this is much better than no labels at all.\n",
    "* additional results show that selecting random labels from a true distribution of labels (instead of a uniform distribution) also helps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
